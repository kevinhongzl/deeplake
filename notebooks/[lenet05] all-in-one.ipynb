{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  [lenet05] All Customization in one Notebook\n",
    "\n",
    "在這個教學裡面，我們示範怎麼把所有元件整合在一起。\n",
    "\n",
    "這樣的使用方法最有彈性，但缺點在於這樣的便利會使我們\n",
    "1. 在開發的過程中寫出耦合度高的元件\n",
    "2. 直接修改程式碼，一次動到實驗中的多個變項。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".cell-output-ipywidget-background {\n",
       "    background-color: transparent !important;\n",
       "}\n",
       ":root {\n",
       "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
       "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
       "}  \n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".cell-output-ipywidget-background {\n",
    "    background-color: transparent !important;\n",
    "}\n",
    ":root {\n",
    "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
    "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
    "}  \n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "SGD 泛化能力好，Adam 收斂速度快，那我們有沒有辦法前期先透過 Adam 訓練，後期再透過 SGD 收斂到一個泛化能力強的神經網絡權重？這個優化方法稱為 SWATS，由 Keskar 和 Socher 在 2017 的 [Improving Generalization Performance by Switching from Adam to SGD](https://arxiv.org/pdf/1712.07628) 提出。\n",
    "\n",
    "在 Keskar 和 Socher 的研究中，SGD 的學習率和切換優化器的時機取決於梯度和超參數。這邊我們為求簡便，不嚴謹地利用 `loss < 2` 作為切換的門檻。\n",
    "\n",
    "修改模板的部分我們以 `# >> Modified` 或 `# -- Modified` 標記。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from functools import partial\n",
    "\n",
    "import warnings\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from modules.base.trainer import BaseTrainer, TrainLogger\n",
    "from modules.base.updater import BaseUpdater\n",
    "from modules.base.validator import BaseValidator\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "import itertools\n",
    "from tqdm.auto import tqdm\n",
    "from modules.base.validator import BaseValidator\n",
    "\n",
    "\n",
    "class CustomTrainer(BaseTrainer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_iter: int = 10000,\n",
    "        eval_step: int = 200,\n",
    "        metric: Metric | None = None,\n",
    "        validator: BaseValidator | None = None,\n",
    "        checkpoint_dir: str = \"./checkpoints/\",\n",
    "        device: Literal[\"cuda\", \"cpu\"] = \"cuda\",\n",
    "        unpack_item: Callable | Literal[\"monai\", \"pytorch\"] = \"pytorch\",\n",
    "        dev: bool = False,\n",
    "    ):\n",
    "        super().__init__(max_iter, eval_step, metric, validator, checkpoint_dir, device, unpack_item, dev)\n",
    "        self.max_iter = max_iter\n",
    "        self.eval_step = eval_step\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.device = device\n",
    "\n",
    "        self.pbar_description = \"Training ({step} / {max_iter} Steps) ({optimizer}) (loss={loss:2.5f})\"\n",
    "\n",
    "        # Setup validator or metric used during training\n",
    "        # 設定驗證器\n",
    "        self.metric = metric\n",
    "        self.validator = validator if validator else BaseValidator(self.metric, is_train=True, device=self.device)\n",
    "        self.metric = self.validator.metric\n",
    "\n",
    "        # The function to unpack the batch into images and targets (based on the __getitem___ of your dataset)\n",
    "        # 設定打開 batch 為 images 和 targets 的函式\n",
    "        if unpack_item == \"pytorch\":\n",
    "            self.unpack_item = lambda batch: (batch[0].to(self.device), batch[1].to(self.device))\n",
    "        elif unpack_item == \"monai\":\n",
    "            self.unpack_item = lambda batch: (batch[\"image\"].to(self.device), batch[\"label\"].to(self.device))\n",
    "        else:\n",
    "            self.unpack_item = unpack_item\n",
    "\n",
    "        # developer mode\n",
    "        # 開發模式\n",
    "        if dev:\n",
    "            self.max_iter = 10\n",
    "            self.eval_step = 3\n",
    "            self.checkpoint_dir = \"./debug/\"\n",
    "            warnings.warn(\n",
    "                \"Trainer will be executed under developer mode. \"\n",
    "                f\"max_iter = {self.max_iter}, \"\n",
    "                f\"eval_step = {self.eval_step}, \"\n",
    "                f\"checkpoint_dir = {self.checkpoint_dir} \",\n",
    "                UserWarning,\n",
    "            )\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        module: nn.Module,\n",
    "        updater: BaseUpdater,\n",
    "        *,\n",
    "        train_dataloader: DataLoader | None = None,\n",
    "        val_dataloader: DataLoader | None = None,\n",
    "    ):\n",
    "        self.show_training_info(module, train_dataloader=train_dataloader, val_dataloader=val_dataloader)\n",
    "\n",
    "        # Initalize progress bar and logger\n",
    "        # 初始化進度條和紀錄器\n",
    "        train_pbar = tqdm(range(self.max_iter), dynamic_ncols=True)\n",
    "        logger = TrainLogger(self.checkpoint_dir)\n",
    "\n",
    "        # Initial stage. Note: updater(module) checks the module and returns a partial func of updating parameters.\n",
    "        # 初始化訓練狀態和更新函式\n",
    "        module.to(self.device)\n",
    "        best_metric = 0\n",
    "        module_update = updater(module)\n",
    "\n",
    "        for step in train_pbar:\n",
    "            module.train()\n",
    "\n",
    "            # Backpropagation\n",
    "            # 反向傳播\n",
    "            batch = next(iter(train_dataloader))\n",
    "            images, targets = self.unpack_item(batch)\n",
    "            loss, opt = module_update(images, targets)  # >> Modified\n",
    "\n",
    "            # Update progress bar and summary writer\n",
    "            # 紀錄目前訓練狀態\n",
    "            info = {\"step\": step + 1, \"max_iter\": self.max_iter, \"loss\": loss, \"optimizer\":opt} # >> Modified\n",
    "            train_pbar.set_description(self.pbar_description.format(**info))\n",
    "            logger.log_train(module.criterion, loss, step)\n",
    "\n",
    "            # Validation\n",
    "            # 驗證目前的網路訓練\n",
    "            if val_dataloader and ((step + 1) % self.eval_step == 0) or (step == self.max_iter - 1):\n",
    "                val_metrics = self.validator(module, val_dataloader, global_step=step)\n",
    "                logger.log_val(self.metric, suffix=[\"Average\"], value=(val_metrics,), step=step)\n",
    "\n",
    "                # Select validation metric\n",
    "                # 指定驗證分數\n",
    "                if val_metrics is not np.nan:\n",
    "                    val_metric = val_metrics\n",
    "\n",
    "                # Update best metric\n",
    "                # 更新驗證分數\n",
    "                if val_metric > best_metric:\n",
    "                    module.save(self.checkpoint_dir)\n",
    "                    logger.success(f\"Model saved! Validation: (New) {val_metric:2.5f} > (Old) {best_metric:2.5f}\")\n",
    "                    best_metric = val_metric\n",
    "                else:\n",
    "                    logger.info(f\"No improvement. Validation: (New) {val_metric:2.5f} <= (Old) {best_metric:2.5f}\")\n",
    "\n",
    "\n",
    "\n",
    "class CustomUpdater(BaseUpdater):\n",
    "    \"\"\"Base class of updaters.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.phase= \"adam\"\n",
    "\n",
    "    def register_module(self, module):\n",
    "        self.check_module(module)\n",
    "        # --- Modified \n",
    "        self.sgd_optimizer = torch.optim.SGD(module.net.parameters(), lr=1)\n",
    "        self.adam_optimizer = torch.optim.Adam(module.net.parameters(), lr=0.001)\n",
    "        module.optimizer = self.adam_optimizer\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(self.sgd_optimizer, T_0=10, T_mult=1, eta_min=0, last_epoch=-1)\n",
    "        module.scheduler = scheduler\n",
    "        # --- Modified\n",
    "        return partial(self.update, module)\n",
    "\n",
    "    def update(self, module, images, targets, **kwargs) -> float:\n",
    "        module.optimizer.zero_grad()\n",
    "        preds = module(images)\n",
    "        loss = module.criterion(preds, targets)\n",
    "        loss.backward()\n",
    "        module.optimizer.step()\n",
    "        # --- Modified \n",
    "        if loss < 2 and self.phase == \"adam\":\n",
    "            self.phase = \"sgd\"\n",
    "            module.optimizer = self.sgd_optimizer\n",
    "        if self.phase == \"sgd\":\n",
    "            module.scheduler.step()\n",
    "        return loss.item(), self.phase\n",
    "        # --- Modified \n",
    "    \n",
    "\n",
    "class CustomValidator(BaseValidator):\n",
    "    def validation(self, module, dataloader, global_step=None):\n",
    "\n",
    "        module.eval()\n",
    "        module.to(self.device)\n",
    "\n",
    "        if not isinstance(dataloader, (list, tuple)):\n",
    "            dataloader = [dataloader]\n",
    "        else:\n",
    "            dataloader = [dl for dl in dataloader if dl is not None]\n",
    "        data_iter = itertools.chain(*dataloader)\n",
    "        pbar = tqdm(\n",
    "            data_iter,\n",
    "            total=sum(len(dl) for dl in dataloader),\n",
    "            dynamic_ncols=True,\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in pbar:\n",
    "                # Infer, decollate data into list of samples, and postprocess both predictions and labels\n",
    "                images, targets = self.unpack_item(batch)\n",
    "\n",
    "                # Get inferred / forwarded results of module\n",
    "                if getattr(module, \"inference\", False) and self.output_infer:\n",
    "                    infer_out = module.inference(images)\n",
    "                else:\n",
    "                    infer_out = module.forward(images)\n",
    "\n",
    "                # Compute validation metrics\n",
    "                batch_metric = self.metric(infer_out, targets).item() # >> Modified\n",
    "\n",
    "                # Update progressbar\n",
    "                info = {\n",
    "                    \"metric_name\": self.metric.__class__.__name__,\n",
    "                    \"batch_metric\": batch_metric,\n",
    "                    \"global_step\": global_step,\n",
    "                }\n",
    "                desc = self.pbar_description.format(**info)\n",
    "                pbar.set_description(desc)\n",
    "\n",
    "        output = self.metric.compute() # >> Modified\n",
    "        self.metric.reset() # >> Modified\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "--------\n",
      "Device: cuda\n",
      "# of Training Samples: 211\n",
      "# of Validation Samples: 47\n",
      "Max iteration: 3000 steps (validates per 3000 steps)\n",
      "Checkpoint directory: ./checkpoints/\n",
      "Evaluation metric: MulticlassAccuracy\n",
      "--------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c02d6879ba4b81b1732b61ef2ea15e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed446b8c4eb4fcf9b3c341be1ef51ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-19 18:21:28.500\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mmodules.base.trainer\u001b[0m:\u001b[36msuccess\u001b[0m:\u001b[36m71\u001b[0m - \u001b[32m\u001b[1mModel saved! Validation: (New) 0.95517 > (Old) 0.00000\u001b[0m\n",
      "\n",
      " Test:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c664b469fc4dbea8c40c421055ced1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9576, device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchmetrics\n",
    "from mnist_dataloaders import train_dataloader, val_dataloader, test_dataloader\n",
    "from lenet import LeNet5\n",
    "\n",
    "\n",
    "validator = CustomValidator(metric=torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=10).to(\"cuda\"))\n",
    "updater = CustomUpdater()\n",
    "trainer = CustomTrainer(max_iter=3000, eval_step=3000, validator=validator)\n",
    "\n",
    "# train\n",
    "print(\"Train:\")\n",
    "lenet = LeNet5().cuda()\n",
    "trainer.train(module=lenet, updater=updater, train_dataloader=train_dataloader, val_dataloader=val_dataloader)\n",
    "\n",
    "# test\n",
    "print(\"\\n Test:\")\n",
    "validator.validation(module=lenet, dataloader=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完成。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
