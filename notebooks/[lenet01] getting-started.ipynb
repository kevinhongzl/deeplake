{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  [lenet01] Tutorial: Image classification - Mnist\n",
    "\n",
    "在這個教學裡面，會教你怎麼透過模組化的 dl 框架來完成訓練。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".cell-output-ipywidget-background {\n",
       "    background-color: transparent !important;\n",
       "}\n",
       ":root {\n",
       "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
       "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
       "}  \n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".cell-output-ipywidget-background {\n",
    "    background-color: transparent !important;\n",
    "}\n",
    ":root {\n",
    "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
    "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
    "}  \n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "首先準備 mnist 資料。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 54000 images in the training data.\n",
      "There are 6000 images in the validation data.\n",
      "There are 10000 images in the testing data.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "\n",
    "train_dataset = MNIST('/files/', train=True, download=True, transform=ToTensor())\n",
    "test_dataset = MNIST('/files/', train=False, download=True, transform=ToTensor())\n",
    "\n",
    "train_dataset, valid_dataset = random_split(train_dataset, [0.9, 0.1], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "print(\"There are\", len(train_dataset), \"images in the training data.\")\n",
    "print(\"There are\", len(valid_dataset), \"images in the validation data.\")\n",
    "print(\"There are\", len(test_dataset), \"images in the testing data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input: torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+uo8KfD3xL4yJbSLAtbqQHuZmEca59z16H7oJr1HVPgNpHh/wNqWqanrdw+oWtu8qshVIAwHyqQVZjz6EZzjFeDV1/wANfBq+OfGEelTSyxWqRPPcSRbdyouBxn1ZlHQ9elfVOsRa5a28WkeEtOsbKPyuLybCw2/PCrEoyx/IDIPPSvJvEvwU8aa9BLqGo+KYdS1JVKrCwZVZAMqoPABznjGO+a8CkRopGjcYZSVI9CK7f4S+LrXwb46hvr5illcQtazuF3bVYgg/QMq59s19OX3jDwhe2clsPGelW/mDHm2+pwq6/Q5OK4LxR8Z/D3hbRjpnhu6m1m+CtGLiS4eRUPI3mR87zkZwODnggV80u7SSNI5yzEkn1JptFFFf/9k=",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA/0lEQVR4AWNgoBOQcf707/9RsGUs6FaW23kw/P//H12YgYGNK+DY978g8C4JXVZqK1gCRBxBlyvdDJf7G40iyShc+wUq98FaT48JRZILpmvDCgsUCRAHKnkknRtDiqPhFkjnm9PiIClpAagCRjDtvAtEPUg+HQKiJx9Z+XobiAEBziB9H+0SVoFoEHgRDJNiYHgNEvj96BOIgoAPVkBZSPAJg4KLSRqhmoGXHSSCJIDBRJX8dSFKxuUQSNHLL0ACIrkGqunbUuncPXYgzpzTUCEGBrBrYW4B0VfU4HIMJo+QZf4+tmdDyDEwuCLLdnkgSwHZVjCtDxwdWdHkBg8XADVQs7jmR9L+AAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First target: 6\n"
     ]
    }
   ],
   "source": [
    "first_image = train_dataset[0][0]\n",
    "print(\"Shape of input:\", first_image.shape)\n",
    "\n",
    "first_image = ToPILImage()(first_image)\n",
    "first_target = train_dataset[0][1]\n",
    "display(first_image)\n",
    "print(\"First target:\", first_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaders\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_dataloader = DataLoader(valid_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks\n",
    "\n",
    "整個訓練 + 測試的流程涉及以下三個類別(Class)\n",
    "\n",
    "* Trainer: 用來管理訓練流程\n",
    "* Validator: 用來計算驗證、測試的指標\n",
    "* Updater: 用來控制更新神經網路的單步 (E.g. 一次反向傳播)\n",
    "\n",
    "我們只需要在原有的 nn.Module 加上一些屬性(例如 optimizer 和 criterion) <br>\n",
    "並製作一個計算驗證指標的函式讓 Validator 使用，<br>\n",
    "就可以開始訓練了！\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=(5, 5), padding=2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.AvgPool2d(kernel_size=(2, 2), stride=2),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=(5, 5)),\n",
    "            nn.Sigmoid(),\n",
    "            nn.AvgPool2d(kernel_size=(2, 2), stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=5*5*16, out_features=120),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(in_features=84, out_features=10)\n",
    "        )\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.net.parameters(), lr=0.001) # called by the updater\n",
    "        self.criterion = nn.CrossEntropyLoss()   # called by the updater\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def inference(self, x):\n",
    "        # called by the validator\n",
    "        preds = self.forward(x)\n",
    "        pred_labels = torch.argmax(preds, dim=1)\n",
    "        return pred_labels\n",
    "    \n",
    "    def save(self, checkpoint_dir):\n",
    "        # called by the validator\n",
    "        Path(checkpoint_dir).mkdir(parents=True, exist_ok=True)\n",
    "        torch.save(self.net.state_dict(), str(Path(checkpoint_dir) / \"net.pth\"))\n",
    "    \n",
    "    def load(self, checkpoint_dir):\n",
    "        # called by the validator\n",
    "        self.net.load_state_dict(torch.load(str(Path(checkpoint_dir) / \"net.pth\")))\n",
    "\n",
    "\n",
    "def batch_acc(pred_labels, targets):\n",
    "    # called by the validator\n",
    "    correct = (pred_labels == targets).sum().item()\n",
    "    total = len(targets)\n",
    "    return torch.tensor(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "--------\n",
      "Device: cuda\n",
      "# of Training Samples: 422\n",
      "# of Validation Samples: 47\n",
      "Max iteration: 1000 steps (validates per 334 steps)\n",
      "Checkpoint directory: ./checkpoints/\n",
      "Evaluation metric: function\n",
      "--------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eba4f8cdb2944d9fa78437bc6b0b6076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af78fde942fb439c9718908193abde72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-17 05:20:43.806\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mmodules.base.trainer\u001b[0m:\u001b[36msuccess\u001b[0m:\u001b[36m71\u001b[0m - \u001b[32m\u001b[1mModel saved! Validation: (New) 0.75404 > (Old) 0.00000\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44cecf5d4bff419684ffec0b41f6fbb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-17 05:20:51.297\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mmodules.base.trainer\u001b[0m:\u001b[36msuccess\u001b[0m:\u001b[36m71\u001b[0m - \u001b[32m\u001b[1mModel saved! Validation: (New) 0.88944 > (Old) 0.75404\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf1137b4dfc449a81d70946db5e7d63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-17 05:20:58.919\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mmodules.base.trainer\u001b[0m:\u001b[36msuccess\u001b[0m:\u001b[36m71\u001b[0m - \u001b[32m\u001b[1mModel saved! Validation: (New) 0.91784 > (Old) 0.88944\u001b[0m\n",
      "\n",
      " Test:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82524a8c22db4451bc426eae629254e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9236550632911392"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "from modules.base.trainer import BaseTrainer\n",
    "from modules.base.updater import BaseUpdater\n",
    "from modules.base.validator import BaseValidator\n",
    "\n",
    "validator = BaseValidator(metric=batch_acc)\n",
    "updater = BaseUpdater()\n",
    "trainer = BaseTrainer(max_iter=1000, eval_step=334, validator=validator)\n",
    "\n",
    "# train\n",
    "print(\"Train:\")\n",
    "lenet = LeNet5().cuda()\n",
    "trainer.train(module=lenet, updater=updater, train_dataloader=train_dataloader, val_dataloader=val_dataloader)\n",
    "\n",
    "# test\n",
    "print(\"\\n Test:\")\n",
    "validator.validation(module=lenet, dataloader=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "搞定！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
